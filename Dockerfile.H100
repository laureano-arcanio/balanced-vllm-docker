FROM nvidia/cuda:12.4.0-runtime-ubuntu22.04

# Set environment variables
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
ENV CUDA_HOME=/usr/local/cuda
ENV PATH=${CUDA_HOME}/bin:${PATH}
ENV LD_LIBRARY_PATH=${CUDA_HOME}/lib64:${LD_LIBRARY_PATH}

# Install system dependencies required for pyenv
RUN apt-get update && apt-get install -y \
    make \
    build-essential \
    libssl-dev \
    zlib1g-dev \
    libbz2-dev \
    libreadline-dev \
    libsqlite3-dev \
    wget \
    curl \
    llvm \
    libncurses5-dev \
    libncursesw5-dev \
    xz-utils \
    tk-dev \
    libffi-dev \
    liblzma-dev \
    git \
    && rm -rf /var/lib/apt/lists/*

# Install pyenv
RUN git clone https://github.com/pyenv/pyenv.git /opt/pyenv

# Set environment variables for pyenv
ENV PYENV_ROOT="/opt/pyenv"
ENV PATH="$PYENV_ROOT/bin:$PATH"

# Initialize pyenv in shell
RUN echo 'eval "$(pyenv init -)"' >> ~/.bashrc

# Install Python 3.12 via pyenv
RUN eval "$(pyenv init -)" && pyenv install 3.12.0 && pyenv global 3.12.0

# Create symbolic links for python and pip to use Python 3.12 from pyenv
RUN ln -sf /opt/pyenv/versions/3.12.0/bin/python3 /usr/bin/python3
RUN ln -sf /opt/pyenv/versions/3.12.0/bin/python3 /usr/bin/python
RUN ln -sf /opt/pyenv/versions/3.12.0/bin/pip3 /usr/bin/pip3
RUN ln -sf /opt/pyenv/versions/3.12.0/bin/pip3 /usr/bin/pip

# Upgrade pip
RUN /opt/pyenv/versions/3.12.0/bin/python3 -m pip install --upgrade pip

# Install uv first using pyenv python
RUN /opt/pyenv/versions/3.12.0/bin/pip install uv

# Create virtual environment using uv with pip seeded
RUN /opt/pyenv/versions/3.12.0/bin/uv venv /opt/venv --python /opt/pyenv/versions/3.12.0/bin/python3 --seed

# Install uv in the virtual environment
RUN /opt/venv/bin/pip install uv

# Install PyTorch with CUDA support
RUN /opt/venv/bin/uv pip install \
    --python /opt/venv/bin/python \
    torch --index-url https://download.pytorch.org/whl/cu124

# Install GPT-OSS vLLM
RUN echo "Installing GPT-OSS vLLM..." && \
    /opt/venv/bin/uv pip install --pre \
        --python /opt/venv/bin/python \
        vllm==0.10.1+gptoss \
        --extra-index-url https://wheels.vllm.ai/gpt-oss/ \
        --extra-index-url https://download.pytorch.org/whl/nightly/cu128 \
        --index-strategy unsafe-best-match \
        "transformers>=4.35.0" accelerate safetensors numpy pyyaml uvicorn fastapi

# Create working directory
WORKDIR /app

# Expose port 8000
EXPOSE 8000

# Set default model environment variable (can be overridden)
ENV MODEL_NAME=facebook/opt-125m

# Create simple startup script
RUN echo '#!/bin/bash\n\
MODEL=${MODEL_NAME:-openai/gpt-oss-20b}\n\
echo "Starting vLLM with model: $MODEL"\n\
/opt/venv/bin/vllm serve \
    "$MODEL" \
    --host 0.0.0.0 \
    --port 8000 \
    --gpu-memory-utilization 0.90 \
    --max-model-len 2048\n' > /app/start.sh && \
    chmod +x /app/start.sh

# Default command
CMD ["/app/start.sh"]